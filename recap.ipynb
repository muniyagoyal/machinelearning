{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[4,7,9,12]\n",
    "\n",
    "y=[6,9,6,10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.xlabel('Time')\n",
    "plt.ylabel('Distance')\n",
    "plt.grid(c='red')\n",
    "plt.plot(x,y)  #  to plot graph in maths way\n",
    "plt.plot(y,x)\n",
    "#plt.bar(x,y) #  to plot graph in bar format \n",
    "#plt.bar(y,x)\n",
    "#plt.show()   #  to show the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "import matplotlib.pyplot   as  plt\n",
    "import  mpld3\n",
    "x=[4,7,9,12]\n",
    "y=[6,9,6,10]\n",
    "\n",
    "players=[\"virat\",\"dhoni\",\"pa\"]\n",
    "runs=[400,450,66]\n",
    "\n",
    "plt.xlabel('Time')\n",
    "plt.ylabel('Distance')\n",
    "plt.grid(c='red')\n",
    "plt.plot(x,y,label=\"danger\")  #  to plot graph in maths way\n",
    "plt.plot(y,x,label=\"smooth\")\n",
    "plt.bar(x,y) #  to plot graph in bar format \n",
    "#plt.bar(players,runs) #  to plot graph in bar format \n",
    "#plt.bar(y,x)\n",
    "plt.scatter(x,y,s=200,marker='x',label=\"mines\")\n",
    "plt.scatter(y,x,s=150,marker='*',label=\"rocks\")\n",
    "plt.legend() #to show scale and  values\n",
    "plt.show()\n",
    "#mpld3.show()# to bring plot as  a popup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris=load_iris()\n",
    "dir(iris)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#feature\n",
    "feature=iris.data\n",
    "#label\n",
    "label=iris.target\n",
    "#calling classifier\n",
    "algo=tree.DecisionTreeClassifier()\n",
    "#training algo\n",
    "trained_algo=algo.fit(feature,label)\n",
    "output=trained_algo.predict([[7.1, 3. , 5.9, 2.1]])\n",
    "print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#handwritten recognnition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "import  matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score\n",
    "import  cv2\n",
    "import numpy as np\n",
    "digit=load_digits()\n",
    "dir(digit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  now  splitting  training and testing dataset testing data 10% \n",
    "split_data=train_test_split(digit.data,digit.target,test_size=0.3)\n",
    "train_data,test_data,train_target,test_target=split_data\n",
    "features=train_data\n",
    "label=train_target\n",
    "\n",
    "#calling algorithm\n",
    "algo=SVC()\n",
    "trained_algo=algo.fit(features,label)\n",
    "output=trained_algo.predict(test_data)\n",
    "result=accuracy_score(test_target,output)\n",
    "print(\"Accuracy score is:\",result)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ncv2.imshow('gray',img)\\ncv2.waitKey(0)\\ncv2.destroyAllWindows()\\n\\n\\n    scaleFactor: Parameter specifying how much the image size is reduced at each image scale or decreses the shape value by 5%\\n    until the face is found smaller this value more is the accuracy.\\n    minNeighbors: Parameter specifying how many neighbors each candidate rectangle should have\""
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "\n",
    "import  cv2\n",
    "import numpy as np\n",
    "import os\n",
    "cap=cv2.VideoCapture(0)\n",
    "#cap=cv2.VideoCapture(\"https://192.168.43.1:8080/video\")\n",
    "#Trainnig our classifier for face detection using haar file(.xml)\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalcatface.xml')\n",
    "eye_cascade = cv2.CascadeClassifier('haarcascade_eye.xml')\n",
    "font=cv2.FONT_ITALIC\n",
    "while cap.isOpened(): \n",
    "    status,frame=cap.read()\n",
    "    grayimg=cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    #detect multiscale is a method to search face rectangle coordinates\n",
    "    faces = face_cascade.detectMultiScale(grayimg,1.05,5)\n",
    "    #faces is actually face value from a video\n",
    "    face_count=len(faces)\n",
    "    #bprint(face_count)\n",
    "    for  (x,y,w,h) in faces:\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),2) \n",
    "        fo_gray=grayimg[y:y+h,x:x+w]\n",
    "        fo_color=frame[y:y+h,x:x+w]\n",
    "        eyes=eye_cascade.detectMultiScale(fo_gray,1.05,5)\n",
    "        for (ex,ey,ew,eh) in eyes:\n",
    "            cv2.rectangle(fo_color,(ex,ey),(ex+ew,ey+eh),(0,0,255),2)\n",
    "    msg=\"Face Detected=\"+str(len(faces))\n",
    "    #puttext(image,msg,(coordinate),fonttype,fontscale,fontcolor,linetype\n",
    "    cv2.putText(frame,msg,(10,50),font,1,(120,0,255),3,cv2.LINE_AA)\t\n",
    "    cv2.imshow('Detect',frame)\n",
    "    #cv2.imshow('Gray',fo_gray)\n",
    "    #cv2.imshow('FaceOnly',fo_color)\n",
    "    if cv2.waitKey(30) & 0xff ==ord('q'):\n",
    "        break\n",
    "voice_output=\"echo Headcount was \"+str(len(faces))+\" | festival --tts\"\n",
    "os.system(voice_output)\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "'''\n",
    "cv2.imshow('gray',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "    scaleFactor: Parameter specifying how much the image size is reduced at each image scale or decreses the shape value by 5%\n",
    "    until the face is found smaller this value more is the accuracy.\n",
    "    minNeighbors: Parameter specifying how many neighbors each candidate rectangle should have'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2,time\n",
    "import numpy\n",
    "first_frame=None\n",
    "cap=cv2.VideoCapture(0)\n",
    "while True:\n",
    "    check,frame=cap.read()\n",
    "    gray=cv2.cvtColor(frame,cv2.COLOR_BGR2GRAY)\n",
    "    gray=cv2.GaussianBlur(gray,(5,5),0)#convert gray image to gaussian blur\n",
    "    if first_frame is None:   #this saves first frame in frame\n",
    "        first_frame=gray\n",
    "        continue\n",
    "    delta_frame=cv2.absdiff(first_frame,gray)#calculate the difference between first frame and other frames\n",
    "    '''provides a threshold value such that it will convert the difference value with less than 30 to black. if the \n",
    "    difference is greater than 30 will convert those pixels to white'''\n",
    "    check,thresh_delta=cv2.threshold(delta_frame,30,255,cv2.THRESH_BINARY)\n",
    "    thresh_dilated=cv2.dilate(thresh_delta ,np.ones((10,10),np.uint8), iterations=3)\n",
    "    #define the contour area basically add the borders\n",
    "    (_,cnts,_)=cv2.findContours(thresh_dilated.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)#define the contour area\n",
    "    #removing noises and shadows\n",
    "    for contour in cnts:\n",
    "        if cv2.contourArea(contour)<1000:\n",
    "            continue\n",
    "        (x,y,w,h)=cv2.boundingRect(contour)\n",
    "        cv2.rectangle(frame,(x,y),(x+w,y+h),(0,255,0),3)\n",
    "    cv2.imshow(\"frame\",frame)\n",
    "    if cv2.waitKey(30) & 0xff ==ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "cap=cv2.VideoCapture(0)\n",
    "#cap=cv2.VideoCapture(\"/home/prempratap/Desktop/ML/move.mp4\") \n",
    "while cap.isOpened():\n",
    "    status,frame1=cap.read()\n",
    "    status,frame2=cap.read()\n",
    "    d=cv2.absdiff(frame1,frame2)\n",
    "    gray=cv2.cvtColor(d,cv2.COLOR_BGR2GRAY)\n",
    "    blur=cv2.GaussianBlur(gray,(5,5),0)\n",
    "    check,thresh_delta=cv2.threshold(blur,30,255,cv2.THRESH_BINARY)\n",
    "    thresh_dilated=cv2.dilate(thresh_delta ,np.ones((2,2),np.uint8), iterations=1)\n",
    "    img,c,h=cv2.findContours(thresh_dilated,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "    font=cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.drawContours(frame1,c,-1,(0,255,0),2)\n",
    "    cv2.imshow(\"motion\",frame1)\n",
    "    \n",
    "    if cv2.waitKey(30) & 0xff ==ord('q'):\n",
    "        break\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
